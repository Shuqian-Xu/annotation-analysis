# annotation-analysis

This repository contains a Python-based framework for comparing news article annotations generated by Large Language Models (LLMs) against human-validated annotations. The goal is to evaluate accuracy across different models and annotation variables.

**Project Overview** \
This project loads JSON annotation files from four different LLMs and human annotators, compares them using various metrics, and stores the results in structured Excel files.

**Project Structure** \
data/ # Contains human annotation files (golden standard), annotation files from Llama 3.1-8b, Phi-4, Qwen 2.5-7b, and Mistral-7b \
output/ # Final comparison results, one Excel file per metric \
scripts/ # Contains scripts necessary for analysis \
main.py # Main execution script

**Features**
1. Ensures that all files in the human annotation folder exist in the corresponding LLM annotation folder.
2. Reads and parses annotation files from both human and LLM folders.
3. Compares annotations with 10 metrics for 18 annotation variables: age, alternativeNames, birthday, descriptiveTexts, directQuotes, inIntro, inTitle,
indirectQuotes, isMain, name, occupations, firstNameOnly, fullName, lastNameOnly, total,
quotedInIntro, quotedInTitle, sex.
4. Writes results to Excel files.

**Implemented Metrics**
1. Metrics for all variable types: \
Exact Match.
2. Metrics for age, firstNameOnly, fullName, lastNameOnly, total (int) \
Numeric Similarity.
3. Metrics for alternativeNames (String array) \
Jaccard Similarity.
4. Metrics for descriptiveTexts, directQuotes, indirectQuotes, occupations (String) \
Normalized Exact Match (ignores case/punctuation), 90% Similarity Match (binary: 1 if similarity â‰¥ 90%), Precision, BLEU-1, Recall, ROUGE-1, F1 Score.

**How to Run the Project**
1. Set up virtual Python environment
2. Ensure that the human annotations and LLM outputs are stored in their respective data/ subfolders
3. Run the main script \
Note: Each time before running the project, make sure the output/ folder contains empty Excel tables with headings only. Empty Excel tables are provided in the empty_output_tables/ folder.

**Expected Output Format** \
One Excel file per metric \
Rows: annotation files \
Columns: annotation variables \
Final rows: mean, median, standard deviation

**Possible Future Improvements** \
Add visualisations \
Add further metrics \
Extend to more LLMs

**Author** \
Shuqian Xu \
M.Sc. Management, Technical University of Munich